{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 2.0 Embeddings Construction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reading cleaned dataframes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "users = pd.read_csv('../data/interim/users.csv')\n",
    "movies = pd.read_csv('../data/interim/movies.csv')\n",
    "ratings = pd.read_csv('../data/interim/ratings.csv')\n",
    "occupations = pd.read_csv('../data/interim/occupations.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Constructing user embeddings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Idea**: I am going to construct the user embeddings using simple One-Hot encoding. I will use the following columns: `gender`, `occupation`, `age`. I will also use the `user_id` column to be able to join the embeddings with the `films` and `ratings` dataframes.\n",
    "\n",
    "`zip-code` column contains too many unique values and the distribution of the values is nearly uniform. Therefore, I will not use this column.\n",
    "\n",
    "Also, `age` column has many different integers. To obtain more information, we can separate all users into 6 age bins:\n",
    "- 0: 0-18\n",
    "- 1: 18-25\n",
    "- 2: 25-35\n",
    "- 3: 35-45\n",
    "- 4: 45-60\n",
    "- 5: 60-75\n",
    "\n",
    "Those clearly show the age groups that are most likely to watch movies."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "users.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gender_cols = ['genderF', 'genderM']\n",
    "age_cols = ['age0_18', 'age18_25', 'age25_35', 'age35_45', 'age45_60', 'age60_75']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "age_mappings = {\n",
    "    0: [0, 18],\n",
    "    1: [18, 25],\n",
    "    2: [25, 35],\n",
    "    3: [35, 45],\n",
    "    4: [45, 60],\n",
    "    5: [60, 75]\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "user_embeddings = pd.DataFrame()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "user_embeddings['user_id'] = users['user_id']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "user_embeddings[gender_cols] = enc.fit_transform(users['gender'].to_numpy().reshape(-1, 1))\n",
    "user_embeddings[occupations['occupation'].tolist()] = enc.fit_transform(users['occupation'].to_numpy().reshape(-1, 1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Splitting age column into 7 columns\n",
    "user_embeddings[age_cols] = users['age'].apply(\n",
    "    lambda x: pd.Series([1 if age_mappings[i][0] <= x < age_mappings[i][1] else 0 for i in range(6)]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "user_embeddings.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here are our user embeddings, which contain all necessary information. Comparing to the original dataframe, we have 30 columns instead of 5."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "user_embeddings.to_csv('../data/processed/user_embeddings.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Constructing movie embeddings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "movies.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Part of work is already done. The `genre` of the film is already one-hot encoded. For the `release_year` column I will also use bin splitting. Movie titles will be encoded using BERT embeddings."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "year_cols = ['year0_1980', 'year1980_1990', 'year1990_1994', 'year1994', 'year1995', 'year1996',\n",
    "             'year1997_2000']\n",
    "year_mappings = {\n",
    "    0: [0, 1980],\n",
    "    1: [1980, 1990],\n",
    "    2: [1990, 1994],\n",
    "    3: [1994, 1995],\n",
    "    4: [1995, 1996],\n",
    "    5: [1996, 1997],\n",
    "    6: [1997, 2000],\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "movie_embeddings = movies.copy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "movie_embeddings[year_cols] = movies['release_year'].apply(\n",
    "    lambda x: pd.Series([1 if year_mappings[i][0] <= x < year_mappings[i][1] else 0 for i in range(7)]))\n",
    "movie_embeddings.drop('release_year', axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "movie_embeddings.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Gettings embeddings for movie titles"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "movie_titles = movie_embeddings['title'].tolist()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "model = BertModel.from_pretrained('bert-base-uncased',\n",
    "                                  output_hidden_states=True)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def bert_text_preparation(text, tokenizer):\n",
    "    \"\"\"\n",
    "    Preprocesses text input in a way that BERT can interpret.\n",
    "    \"\"\"\n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    segments_ids = [1] * len(indexed_tokens)\n",
    "    # convert inputs to tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensor = torch.tensor([segments_ids])\n",
    "    return tokens_tensor, segments_tensor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_bert_embeddings(tokens_tensor, segments_tensor, model):\n",
    "    \"\"\"\n",
    "    Obtains BERT embeddings for tokens.\n",
    "    \"\"\"\n",
    "    # gradient calculation id disabled\n",
    "    with torch.no_grad():\n",
    "        # obtain hidden states\n",
    "        outputs = model(tokens_tensor, segments_tensor)\n",
    "        hidden_states = outputs[2]\n",
    "    # concatenate the tensors for all layers\n",
    "    # use \"stack\" to create new dimension in tensor\n",
    "    token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "    # remove dimension 1, the \"batches\"\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "    # swap dimensions 0 and 1 so we can loop over tokens\n",
    "    token_embeddings = token_embeddings.permute(1,0,2)\n",
    "    # intialized list to store embeddings\n",
    "    token_vecs_sum = []\n",
    "    # \"token_embeddings\" is a [Y x 12 x 768] tensor\n",
    "    # where Y is the number of tokens in the sentence\n",
    "    # loop over tokens in sentence\n",
    "    for token in token_embeddings:\n",
    "        # \"token\" is a [12 x 768] tensor\n",
    "        # sum the vectors from the last four layers\n",
    "        sum_vec = torch.sum(token[-4:], dim=0)\n",
    "        token_vecs_sum.append(sum_vec)\n",
    "    return token_vecs_sum"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bert_embeddings_list = [\n",
    "    sum(get_bert_embeddings(*bert_text_preparation(title, tokenizer), model)).numpy()\n",
    "    for title in movie_titles\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bert_embeddings = pd.DataFrame(bert_embeddings_list, columns=[f'bert{i}' for i in range(768)])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bert_embeddings.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "movie_embeddings = pd.concat([movie_embeddings, bert_embeddings], axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "movie_embeddings.drop('title', axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "movie_embeddings.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Joining embeddings with ratings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ratings.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ratings_embeddings = ratings.merge(user_embeddings, on='user_id', how='left')\n",
    "ratings_embeddings = ratings_embeddings.merge(movie_embeddings, on='item_id', how='left')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ratings_embeddings.drop(['user_id', 'item_id', 'timestamp'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ratings_embeddings.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ratings_embeddings.to_csv('../data/processed/ratings_embeddings.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.read_csv('../data/processed/ratings_embeddings.csv').head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Splitting data into train and test for baseline model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(ratings_embeddings, test_size=0.2, random_state=42, stratify=ratings_embeddings['rating'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "So, my idea is to train some model to predict the rating based on the user and movie embeddings. Then, I will recommend the movies with the highest predicted ratings to the user."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As baseline model I will use Decision Tree Classifier. It sounds reasonable to use it, because it is easy to interpret and it is not prone to overfitting."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42, max_depth=5)\n",
    "\n",
    "clf.fit(train.drop('rating', axis=1), train['rating'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clf.score(test.drop('rating', axis=1), test['rating'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(test['rating'], clf.predict(test.drop('rating', axis=1))))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plotting tree"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plot_tree(clf, feature_names=train.drop('rating', axis=1).columns, fontsize=10)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
